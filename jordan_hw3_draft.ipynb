{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ea2675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e2a9a5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01724138 0.03448276 0.05172414 0.06896552 0.0862069\n",
      " 0.10344828 0.12068966 0.13793103 0.15517241 0.17241379 0.18965517\n",
      " 0.20689655 0.22413793 0.24137931 0.25862069 0.27586207 0.29310345\n",
      " 0.31034483 0.32758621 0.34482759 0.36206897 0.37931034 0.39655172\n",
      " 0.4137931  0.43103448 0.44827586 0.46551724 0.48275862 0.5       ]\n",
      "[74493.29389624 80049.86998155 82801.91894734 81184.48730159\n",
      " 80903.23401794 78229.00148686 84941.27270699 77811.04793429\n",
      " 76739.91115542 79655.14893686 77344.51727082 84711.82813555\n",
      " 81053.39039944 88895.73809576 81891.26405744 80831.90707695\n",
      " 79523.16370202 78276.13292682 75492.27087912 83717.60753761\n",
      " 80056.09381117 84660.61003105 79434.03528683 90021.2886381\n",
      " 77855.4684022  84366.53950088 87959.01568351 95649.38025641\n",
      " 91844.87868122 92301.30679516]\n",
      "Number of folds for cross-validation: 5\n",
      "Best parameter for Dropout with MSE loss: 0.0\n",
      "Average MSE error for the best Dropout parameter: 74493.29389624108\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate  data\n",
    "X, Y = make_regression(n_samples=1200, n_features=30,  n_informative = 18, noise=10, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree \n",
    "blackbox = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# test on tuneBlackBox\n",
    "best_param = tuneBlackBox(blackbox, X, Y, 'Dropout',  5, 'MSE', monteCarloReplicates = 100 )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da77f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuneBlackBox(blackbox, X, Y, regularization, n_folds, loss, monteCarloReplicates = 10, columnBounds = 10):\n",
    "    \n",
    "    #split X, Y into k folds\n",
    "    kf = KFold(n_splits = n_folds)\n",
    "    \n",
    "    #Modify code for selected regularization\n",
    "    if (regularization == 'Dropout'):\n",
    "        regParam = np.linspace(0, .5, 30)\n",
    "        regularization_function = DropoutRegularization \n",
    "                           \n",
    "    elif (regularization == 'NoiseAddition'):\n",
    "       # regParam =  tbd\n",
    "        regularization_function = NoiseAdditionRegularization \n",
    "\n",
    "        print('need to add stuff')\n",
    "    else: \n",
    "        #regParam = tbd\n",
    "        regularization_function = RobustRegularization \n",
    "        print('need to add stuff')\n",
    "\n",
    "    #results array with length of number of parameters to test    \n",
    "    results = np.zeros(len(regParam))\n",
    "\n",
    "    #all regularizations may require normalization of data. may want to create normlaization function to be called before calling regularization\n",
    "    \n",
    "    \n",
    "    # parameters to test in cross validation\n",
    "    for index, param in enumerate(regParam):\n",
    "        cumulative_error = 0\n",
    "        \n",
    "        #train / fit n_fold times in cross validation                   \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "                             \n",
    "            error = regularization_function(X_train, Y_train, X_test, Y_test, monteCarloReplicates, param, blackbox, loss)\n",
    "            \n",
    "            # Add error to cumulative error\n",
    "            cumulative_error = cumulative_error + error\n",
    "            \n",
    "        #add error divided by number of folds to cross-val results array\n",
    "        results[index] = cumulative_error / n_folds\n",
    "            \n",
    "    # Find the parameter that minimizes the loss and its error\n",
    "    min_error_index = np.argmin(results)\n",
    "    best_param = regParam[min_error_index]\n",
    "    best_error = results[min_error_index]\n",
    "\n",
    "    #print(regParam)\n",
    "    #print(results)\n",
    "    \n",
    "    # Print the best parameter and its error\n",
    "    print(f\"Number of folds for cross-validation: {n_folds}\")\n",
    "    print(f\"Best parameter for {regularization} with {loss} loss: {best_param}\")\n",
    "    print(f\"Average {loss} error for the best {regularization} parameter: {best_error}\")\n",
    "\n",
    "    return best_param    \n",
    "    #have to return trained model as well\n",
    "\n",
    "        \n",
    "\n",
    "                               \n",
    "                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc28bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropoutRegularization(X_train, Y_train, X_test, Y_test, monteCarloReplicates, dropoutParam, blackbox, loss):\n",
    "    \n",
    "    \n",
    "    #need to normalize data\n",
    "    \n",
    "    X_train_all_dropout = []\n",
    "    Y_train_all_replicated = []\n",
    "    \n",
    "    for i in range(monteCarloReplicates): \n",
    "        #define a mask to subsample/dropout training data. Right now, defined a .2 dropout parameter as \n",
    "        #an 80% probability of retainment, / 20% probability of dropout. Can adjust this depending on common meaning of dropout.\n",
    "        \n",
    "        dropout_mask = np.random.rand(*X_train.shape) < dropoutParam\n",
    "        #make copy of X_train so we don't overwrite original X_train with dropout mask\n",
    "        X_train_dropout = X_train.copy()\n",
    "        X_train_dropout[dropout_mask] = 0\n",
    "        if (dropoutParam!=0):\n",
    "            X_train_dropout = X_train_dropout / (1 - dropoutParam)  \n",
    "            \n",
    "        X_train_all_dropout.append(X_train_dropout)\n",
    "        Y_train_all_replicated.append(Y_train)            \n",
    "            \n",
    "    # Concatenate to form a single large training dataset and label set\n",
    "    X_train_concatenated = np.concatenate(X_train_all_dropout, axis=0)\n",
    "    Y_train_concatenated = np.concatenate(Y_train_all_replicated, axis=0)\n",
    "    \n",
    "    # Fit the model on the concatenated dataset\n",
    "    fitted_model = blackbox.fit(X_train_concatenated, Y_train_concatenated)\n",
    "    \n",
    "    # Predict on the test set and calculate loss\n",
    "    y_pred = fitted_model.predict(X_test)       \n",
    "    #calculate loss with the input loss metric\n",
    "    if loss == 'MSE':\n",
    "        error = mean_squared_error(Y_test, y_pred)\n",
    "    if loss == 'MAD':\n",
    "        error = mean_absolute_error(Y_test, y_pred)\n",
    "        \n",
    "    \n",
    "    #average error over the M montecarlo replicates\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555c5059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def NoiseAdditionRegularization():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ac06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "                           \n",
    "#def RobustRegularization():\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
